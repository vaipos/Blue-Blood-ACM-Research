{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "420a9f3e",
   "metadata": {},
   "source": [
    "# Statistical tests with graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7ba8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "# Define your bucket name and file key (file path in S3)\n",
    "BUCKET_NAME = \"blue-blood-data\"\n",
    "FILE_KEY = \"final_df.csv\"  # Change to your actual file path in S3\n",
    "\n",
    "# Create an S3 client\n",
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "# Fetch the file from S3\n",
    "response = s3.get_object(Bucket=BUCKET_NAME, Key=FILE_KEY)\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "csv_content = response[\"Body\"].read().decode(\"utf-8\")\n",
    "df = pd.read_csv(StringIO(csv_content))\n",
    "\n",
    "# Print DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1060a55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = ['subject_id', 'pre_charttime', 'prescription_start', 'post_charttime'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8938487",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "def clean_and_convert(x):\n",
    "    if pd.notna(x):\n",
    "        try:\n",
    "            # Remove square brackets if they exist\n",
    "            x = re.sub(r'[\\[\\]]', '', x)\n",
    "            # Replace multiple spaces with a single space\n",
    "            cleaned = re.sub(r'\\s+', ' ', x.strip())\n",
    "            # Convert to numpy array of floats\n",
    "            return np.array([float(i) for i in cleaned.split(' ')])\n",
    "        except Exception as e:\n",
    "            # If there's an error during conversion, print the error and return the original value\n",
    "            print(f\"Error processing value: {x}. Error: {e}\")\n",
    "            return x  # Return the original value in case of error\n",
    "    return x  # If NaN, return as is\n",
    "\n",
    "# Check the values before applying the function\n",
    "print(df['prescription_rx_embeddings'].head())\n",
    "\n",
    "# Apply the function to the 'prescription_rx_embeddings' column\n",
    "df['prescription_rx_embeddings'] = df['prescription_rx_embeddings'].apply(clean_and_convert)\n",
    "\n",
    "# Check the result\n",
    "print(df['prescription_rx_embeddings'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac94ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the 'prescription_rx_embeddings' column into separate columns based on array elements\n",
    "expanded_columns = pd.DataFrame(df['prescription_rx_embeddings'].tolist(), index=df.index)\n",
    "\n",
    "# Optionally, rename the columns to something meaningful\n",
    "expanded_columns.columns = [f'P{i}' for i in range(expanded_columns.shape[1])]\n",
    "\n",
    "# Concatenate the expanded columns back to the original DataFrame, if needed\n",
    "df = pd.concat([df, expanded_columns], axis=1)\n",
    "\n",
    "# Drop the original 'prescription_rx_embeddings' column\n",
    "df.drop(columns=['prescription_rx_embeddings'], inplace=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c44e2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import tarfile\n",
    "import os\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "\n",
    "# S3 bucket and key extraction\n",
    "s3_uri = \"s3://sagemaker-us-east-1-211125439249/pytorch-training-2025-03-21-04-33-20-724/output/output.tar.gz\"\n",
    "parts = s3_uri.replace(\"s3://\", \"\").split(\"/\")\n",
    "bucket_name = parts[0]\n",
    "key = \"/\".join(parts[1:])\n",
    "\n",
    "# Initialize S3 client\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Download the .tar.gz file\n",
    "response = s3.get_object(Bucket=bucket_name, Key=key)\n",
    "file_obj = BytesIO(response['Body'].read())\n",
    "\n",
    "# Extract the .tar.gz file\n",
    "with tarfile.open(fileobj=file_obj, mode='r:gz') as tar:\n",
    "    for member in tar.getmembers():\n",
    "        if \"synthetic_data.csv\" in member.name:\n",
    "            csv_file = tar.extractfile(member)\n",
    "            df_synthetic = pd.read_csv(csv_file)\n",
    "            break\n",
    "\n",
    "# Display the DataFrame\n",
    "df_synthetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23be9993",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import skew, kurtosis, chi2_contingency\n",
    "\n",
    "# Function to calculate mean\n",
    "def calculate_mean(df1, df2):\n",
    "    return df1.mean(), df2.mean()\n",
    "\n",
    "# Function to calculate median\n",
    "def calculate_median(df1, df2):\n",
    "    return df1.median(), df2.median()\n",
    "\n",
    "# Function to calculate standard deviation\n",
    "def calculate_std(df1, df2):\n",
    "    return df1.std(), df2.std()\n",
    "\n",
    "# Function to calculate skewness\n",
    "def calculate_skewness(df1, df2):\n",
    "    return df1.apply(lambda x: skew(x, nan_policy='omit')), df2.apply(lambda x: skew(x, nan_policy='omit'))\n",
    "\n",
    "# Function to calculate kurtosis\n",
    "def calculate_kurtosis(df1, df2):\n",
    "    return df1.apply(lambda x: kurtosis(x, nan_policy='omit')), df2.apply(lambda x: kurtosis(x, nan_policy='omit'))\n",
    "\n",
    "# Function to calculate Chi-Square Test for categorical data\n",
    "def calculate_chi_square(df1, df2, cat_column1, cat_column2):\n",
    "    # Create contingency tables for both DataFrames\n",
    "    contingency_table1 = pd.crosstab(df1[cat_column1], df1[cat_column2])\n",
    "    contingency_table2 = pd.crosstab(df2[cat_column1], df2[cat_column2])\n",
    "    \n",
    "    # Perform Chi-Square test for both\n",
    "    chi2_stat1, p_value1, dof1, expected1 = chi2_contingency(contingency_table1)\n",
    "    chi2_stat2, p_value2, dof2, expected2 = chi2_contingency(contingency_table2)\n",
    "    \n",
    "    # Return the results\n",
    "    return {\n",
    "        \"Chi2 Statistic (df)\": chi2_stat1,\n",
    "        \"P-value (df)\": p_value1,\n",
    "        \"Degrees of Freedom (df)\": dof1,\n",
    "        \"Expected Frequencies (df)\": expected1,\n",
    "        \"Chi2 Statistic (new df)\": chi2_stat2,\n",
    "        \"P-value (new df)\": p_value2,\n",
    "        \"Degrees of Freedom (new df)\": dof2,\n",
    "        \"Expected Frequencies (new df)\": expected2\n",
    "    }\n",
    "\n",
    "# Perform the statistical analysis and print the results:\n",
    "\n",
    "print(\"Mean Comparison between Original and New DataFrame:\")\n",
    "mean_df, mean_new_df = calculate_mean(df, df_synthetic)\n",
    "print(\"Original DataFrame Mean:\\n\", mean_df)\n",
    "print(\"New DataFrame Mean:\\n\", mean_new_df)\n",
    "\n",
    "print(\"\\nMedian Comparison between Original and New DataFrame:\")\n",
    "median_df, median_new_df = calculate_median(df, df_synthetic)\n",
    "print(\"Original DataFrame Median:\\n\", median_df)\n",
    "print(\"New DataFrame Median:\\n\", median_new_df)\n",
    "\n",
    "print(\"\\nStandard Deviation Comparison between Original and New DataFrame:\")\n",
    "std_df, std_new_df = calculate_std(df, df_synthetic)\n",
    "print(\"Original DataFrame Standard Deviation:\\n\", std_df)\n",
    "print(\"New DataFrame Standard Deviation:\\n\", std_new_df)\n",
    "\n",
    "print(\"\\nSkewness Comparison between Original and New DataFrame:\")\n",
    "skew_df, skew_new_df = calculate_skewness(df, df_synthetic)\n",
    "print(\"Original DataFrame Skewness:\\n\", skew_df)\n",
    "print(\"New DataFrame Skewness:\\n\", skew_new_df)\n",
    "\n",
    "print(\"\\nKurtosis Comparison between Original and New DataFrame:\")\n",
    "kurt_df, kurt_new_df = calculate_kurtosis(df, df_synthetic)\n",
    "print(\"Original DataFrame Kurtosis:\\n\", kurt_df)\n",
    "print(\"New DataFrame Kurtosis:\\n\", kurt_new_df)\n",
    "\n",
    "# If you have categorical columns, you can perform the Chi-Square test for both DataFrames\n",
    "print(\"\\nChi-Square Test between prescription_dose_val_rx and prescription_dose_unit_rx:\")\n",
    "chi_square_results = calculate_chi_square(df, df_synthetic, 'prescription_dose_val_rx', 'prescription_dose_unit_rx')\n",
    "print(chi_square_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea53319",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_statistics(real_data, synthetic_data):\n",
    "    # Initialize dictionaries to store results\n",
    "    mean_differences = {}\n",
    "    real_means = {}\n",
    "    synthetic_means = {}\n",
    "\n",
    "    # Iterate through columns\n",
    "    for col in real_data.columns:\n",
    "        try:\n",
    "            # Only calculate statistics for numerical columns\n",
    "            if pd.api.types.is_numeric_dtype(real_data[col]):\n",
    "                real_mean = real_data[col].mean()\n",
    "                synthetic_mean = synthetic_data[col].mean()\n",
    "\n",
    "                real_means[col] = real_mean  # Store mean of real data\n",
    "                synthetic_means[col] = synthetic_mean  # Store mean of synthetic data\n",
    "                mean_differences[col] = abs(real_mean - synthetic_mean)  # Store absolute mean difference\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing column {col}: {e}\")\n",
    "\n",
    "    # Create DataFrames for the results\n",
    "    mean_diff_df = pd.DataFrame(list(mean_differences.items()), columns=['Column', 'Mean Difference'])\n",
    "    avg_values_df = pd.DataFrame({'Column': list(real_means.keys()), \n",
    "                                  'Real Data Mean': list(real_means.values()), \n",
    "                                  'Synthetic Data Mean': list(synthetic_means.values())})\n",
    "\n",
    "    return mean_diff_df, avg_values_df\n",
    "\n",
    "mean_diff_df, avg_values_df = compute_statistics(df, df_synthetic)\n",
    "\n",
    "# Print the tables\n",
    "print(\"\\nðŸ”¹ Mean Differences Between Real & Synthetic Data:\")\n",
    "print(mean_diff_df)\n",
    "\n",
    "print(\"\\nðŸ”¹ Average Values in Real & Synthetic Data:\")\n",
    "print(avg_values_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c42c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define real and synthetic data\n",
    "real_data = df\n",
    "synthetic_data = df_synthetic\n",
    "\n",
    "# Prepare a list to store results\n",
    "results = []\n",
    "\n",
    "# Iterate through all numerical columns\n",
    "for column in real_data.select_dtypes(include=['number']).columns:\n",
    "    real_mean = real_data[column].mean()\n",
    "    synthetic_mean = synthetic_data[column].mean()\n",
    "    abs_difference = abs(real_mean - synthetic_mean)\n",
    "    \n",
    "    # Calculate a simple distribution difference using KL Divergence (if possible)\n",
    "    distribution_diff = abs(real_data[column].std() - synthetic_data[column].std())  \n",
    "\n",
    "    # Append results\n",
    "    results.append([column, real_mean, synthetic_mean, abs_difference, distribution_diff])\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "summary_df = pd.DataFrame(\n",
    "    results, columns=['Column', 'Real Mean', 'Synthetic Mean', 'Abs Difference', 'Distribution Difference']\n",
    ")\n",
    "\n",
    "# Format numbers to avoid scientific notation\n",
    "summary_df[['Real Mean', 'Synthetic Mean', 'Abs Difference', 'Distribution Difference']] = summary_df[\n",
    "    ['Real Mean', 'Synthetic Mean', 'Abs Difference', 'Distribution Difference']\n",
    "].applymap(lambda x: f\"{x:,.6f}\")\n",
    "\n",
    "# Display the table\n",
    "print(summary_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48390283",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "chunk_size = 25\n",
    "columns = df.columns  # List of columns to process\n",
    "\n",
    "# Function to calculate mean\n",
    "def calculate_mean(df1, df2):\n",
    "    return df1.mean(), df2.mean()\n",
    "\n",
    "# Function to calculate median\n",
    "def calculate_median(df1, df2):\n",
    "    return df1.median(), df2.median()\n",
    "\n",
    "# Function to calculate standard deviation\n",
    "def calculate_std(df1, df2):\n",
    "    return df1.std(), df2.std()\n",
    "\n",
    "# Function to calculate skewness\n",
    "def calculate_skewness(df1, df2):\n",
    "    return df1.apply(lambda x: skew(x, nan_policy='omit')), df2.apply(lambda x: skew(x, nan_policy='omit'))\n",
    "\n",
    "# Function to calculate kurtosis\n",
    "def calculate_kurtosis(df1, df2):\n",
    "    return df1.apply(lambda x: kurtosis(x, nan_policy='omit')), df2.apply(lambda x: kurtosis(x, nan_policy='omit'))\n",
    "\n",
    "# Function to plot chunked bar charts in a 3x3 grid\n",
    "def plot_chunked_barcharts(stat_func, stat_label, df1, df2, columns, chunk_size=25):\n",
    "    column_chunks = np.array_split(columns, len(columns) // chunk_size + 1)\n",
    "    \n",
    "    num_plots = len(column_chunks)\n",
    "    rows = (num_plots // 3) + (1 if num_plots % 3 else 0)\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, 3, figsize=(15, rows * 5))  # Create grid\n",
    "    axes = axes.flatten()  # Flatten for easy iteration\n",
    "    \n",
    "    used_axes = 0  # Track used subplots\n",
    "\n",
    "    for idx, chunk in enumerate(column_chunks):\n",
    "        if idx >= len(axes):  # Prevent errors if more chunks than axes\n",
    "            break\n",
    "\n",
    "        stat_df1, stat_df2 = stat_func(df1[chunk], df2[chunk])\n",
    "        stats_df = pd.DataFrame({\"Original\": stat_df1, \"New\": stat_df2})\n",
    "        stats_df.dropna(how=\"all\", inplace=True)  # Remove empty columns\n",
    "\n",
    "        if not stats_df.empty:\n",
    "            stats_df.plot(kind=\"bar\", alpha=0.7, ax=axes[idx], title=f\"{stat_label} ({chunk[0]} to {chunk[-1]})\")\n",
    "            used_axes += 1\n",
    "\n",
    "    # Hide any unused subplots\n",
    "    for idx in range(used_axes, len(axes)):\n",
    "        fig.delaxes(axes[idx])\n",
    "\n",
    "    plt.tight_layout()  # Adjust layout\n",
    "\n",
    "# Call the functions to generate the charts\n",
    "plot_chunked_barcharts(calculate_mean, \"Mean\", df, df_synthetic, columns, chunk_size)\n",
    "plot_chunked_barcharts(calculate_median, \"Median\", df, df_synthetic, columns, chunk_size)\n",
    "plot_chunked_barcharts(calculate_std, \"Standard Deviation\", df, df_synthetic, columns, chunk_size)\n",
    "plot_chunked_barcharts(calculate_skewness, \"Skewness\", df, df_synthetic, columns, chunk_size)\n",
    "plot_chunked_barcharts(calculate_kurtosis, \"Kurtosis\", df, df_synthetic, columns, chunk_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afecd266",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "chunk_size = 10\n",
    "columns = df.columns  # List of columns to process\n",
    "\n",
    "# Function to calculate mean\n",
    "def calculate_mean(df1, df2):\n",
    "    return df1.mean(), df2.mean()\n",
    "\n",
    "# Function to calculate median\n",
    "def calculate_median(df1, df2):\n",
    "    return df1.median(), df2.median()\n",
    "\n",
    "# Function to calculate standard deviation\n",
    "def calculate_std(df1, df2):\n",
    "    return df1.std(), df2.std()\n",
    "\n",
    "# Function to calculate skewness\n",
    "def calculate_skewness(df1, df2):\n",
    "    return df1.apply(lambda x: skew(x, nan_policy='omit')), df2.apply(lambda x: skew(x, nan_policy='omit'))\n",
    "\n",
    "# Function to calculate kurtosis\n",
    "def calculate_kurtosis(df1, df2):\n",
    "    return df1.apply(lambda x: kurtosis(x, nan_policy='omit')), df2.apply(lambda x: kurtosis(x, nan_policy='omit'))\n",
    "\n",
    "# Function to plot error differences in a 3x3 grid\n",
    "def plot_error_difference_grid(stat_func, stat_label, df1, df2, columns, chunk_size=10):\n",
    "    column_chunks = np.array_split(columns, len(columns) // chunk_size + 1)\n",
    "    \n",
    "    num_plots = 0  # Count non-empty plots\n",
    "    filtered_chunks = []  # Store only valid chunks\n",
    "\n",
    "    for chunk in column_chunks:\n",
    "        stat_df1, stat_df2 = stat_func(df1[chunk], df2[chunk])\n",
    "        error_diff = abs(stat_df1 - stat_df2)\n",
    "        non_zero_error_columns = error_diff[error_diff > 0]\n",
    "\n",
    "        if not non_zero_error_columns.empty:\n",
    "            filtered_chunks.append((non_zero_error_columns, chunk))\n",
    "            num_plots += 1\n",
    "\n",
    "    # Determine grid size\n",
    "    rows = (num_plots // 3) + (1 if num_plots % 3 else 0)\n",
    "    fig, axes = plt.subplots(rows, 3, figsize=(15, rows * 5))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for idx, (non_zero_error_columns, chunk) in enumerate(filtered_chunks):\n",
    "        ax = axes[idx]\n",
    "        ax.bar(non_zero_error_columns.index, non_zero_error_columns.values, alpha=0.7, color='red')\n",
    "        ax.set_title(f\"{stat_label} Error Diff ({chunk[0]} to {chunk[-1]})\")\n",
    "        ax.set_xlabel(\"Columns\")\n",
    "        ax.set_ylabel(f\"{stat_label} Error Difference\")\n",
    "        ax.tick_params(axis='x', rotation=90)\n",
    "\n",
    "    # Remove unused subplots\n",
    "    for idx in range(num_plots, len(axes)):\n",
    "        fig.delaxes(axes[idx])\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "# Call the function to plot error differences\n",
    "plot_error_difference_grid(calculate_mean, \"Mean\", df, df_synthetic, columns, chunk_size)\n",
    "plot_error_difference_grid(calculate_median, \"Median\", df, df_synthetic, columns, chunk_size)\n",
    "plot_error_difference_grid(calculate_std, \"Standard Deviation\", df, df_synthetic, columns, chunk_size)\n",
    "plot_error_difference_grid(calculate_skewness, \"Skewness\", df, df_synthetic, columns, chunk_size)\n",
    "plot_error_difference_grid(calculate_kurtosis, \"Kurtosis\", df, df_synthetic, columns, chunk_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bb_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
