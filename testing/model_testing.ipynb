{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/bb_dev/lib/python3.12/site-packages/pydantic/_internal/_fields.py:192: UserWarning: Field name \"json\" in \"MonitoringDatasetFormat\" shadows an attribute in parent \"Base\"\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/10/25 02:14:28] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials in shared credentials file: ~<span style=\"color: #e100e1; text-decoration-color: #e100e1\">/.aws/credentials</span>   <a href=\"file:///opt/anaconda3/envs/bb_dev/lib/python3.12/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/bb_dev/lib/python3.12/site-packages/botocore/credentials.py#1278\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1278</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/10/25 02:14:28]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials in shared credentials file: ~\u001b[38;2;225;0;225m/.aws/\u001b[0m\u001b[38;2;225;0;225mcredentials\u001b[0m   \u001b]8;id=956380;file:///opt/anaconda3/envs/bb_dev/lib/python3.12/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=625827;file:///opt/anaconda3/envs/bb_dev/lib/python3.12/site-packages/botocore/credentials.py#1278\u001b\\\u001b[2m1278\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/ubaid/Library/Application Support/sagemaker/config.yaml\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/10/25 02:14:29] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials in shared credentials file: ~<span style=\"color: #e100e1; text-decoration-color: #e100e1\">/.aws/credentials</span>   <a href=\"file:///opt/anaconda3/envs/bb_dev/lib/python3.12/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/bb_dev/lib/python3.12/site-packages/botocore/credentials.py#1278\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1278</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/10/25 02:14:29]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials in shared credentials file: ~\u001b[38;2;225;0;225m/.aws/\u001b[0m\u001b[38;2;225;0;225mcredentials\u001b[0m   \u001b]8;id=452066;file:///opt/anaconda3/envs/bb_dev/lib/python3.12/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=63846;file:///opt/anaconda3/envs/bb_dev/lib/python3.12/site-packages/botocore/credentials.py#1278\u001b\\\u001b[2m1278\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials in shared credentials file: ~<span style=\"color: #e100e1; text-decoration-color: #e100e1\">/.aws/credentials</span>   <a href=\"file:///opt/anaconda3/envs/bb_dev/lib/python3.12/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/bb_dev/lib/python3.12/site-packages/botocore/credentials.py#1278\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1278</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials in shared credentials file: ~\u001b[38;2;225;0;225m/.aws/\u001b[0m\u001b[38;2;225;0;225mcredentials\u001b[0m   \u001b]8;id=675888;file:///opt/anaconda3/envs/bb_dev/lib/python3.12/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=254717;file:///opt/anaconda3/envs/bb_dev/lib/python3.12/site-packages/botocore/credentials.py#1278\u001b\\\u001b[2m1278\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attached AdministratorAccess policy to role: arn:aws:iam::211125439249:role/service-role/AmazonSageMaker-ExecutionRole-20250314T153928\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/10/25 02:14:30] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Skipping checksum validation. Response did not contain one of the  <a href=\"file:///opt/anaconda3/envs/bb_dev/lib/python3.12/site-packages/botocore/httpchecksum.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">httpchecksum.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/bb_dev/lib/python3.12/site-packages/botocore/httpchecksum.py#481\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">481</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         following algorithms: <span style=\"font-weight: bold\">[</span><span style=\"color: #008700; text-decoration-color: #008700\">'crc32'</span>, <span style=\"color: #008700; text-decoration-color: #008700\">'sha1'</span>, <span style=\"color: #008700; text-decoration-color: #008700\">'sha256'</span><span style=\"font-weight: bold\">]</span>.                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/10/25 02:14:30]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Skipping checksum validation. Response did not contain one of the  \u001b]8;id=593019;file:///opt/anaconda3/envs/bb_dev/lib/python3.12/site-packages/botocore/httpchecksum.py\u001b\\\u001b[2mhttpchecksum.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=777956;file:///opt/anaconda3/envs/bb_dev/lib/python3.12/site-packages/botocore/httpchecksum.py#481\u001b\\\u001b[2m481\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         following algorithms: \u001b[1m[\u001b[0m\u001b[38;2;0;135;0m'crc32'\u001b[0m, \u001b[38;2;0;135;0m'sha1'\u001b[0m, \u001b[38;2;0;135;0m'sha256'\u001b[0m\u001b[1m]\u001b[0m.                 \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from io import StringIO\n",
    "import sagemaker\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sagemaker.pytorch import PyTorch\n",
    "import os\n",
    "\n",
    "boto_session = boto3.Session(region_name='us-east-1')\n",
    "sagemaker_session = sagemaker.Session(boto_session=boto_session)\n",
    "\n",
    "role = \"arn:aws:iam::211125439249:role/service-role/AmazonSageMaker-ExecutionRole-20250314T153928\"\n",
    "role_name = role.split('/')[-1]  # Extract just the role name from the ARN\n",
    "\n",
    "# Attach AdministratorAccess policy to your existing role\n",
    "iam_client = boto3.client('iam')\n",
    "iam_client.attach_role_policy(\n",
    "    RoleName=role_name,\n",
    "    PolicyArn=\"arn:aws:iam::aws:policy/AdministratorAccess\"\n",
    ")\n",
    "print(f\"Attached AdministratorAccess policy to role: {role}\")\n",
    "\n",
    "input_data_s3_uri = \"s3://blue-blood-data/final_df.csv\"\n",
    "\n",
    "# Define your bucket name and file key (file path in S3)\n",
    "BUCKET_NAME = \"blue-blood-data\"\n",
    "FILE_KEY = \"final_df.csv\"  # Change to your actual file path in S3\n",
    "\n",
    "# Create an S3 client\n",
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "# Fetch the file from S3\n",
    "response = s3.get_object(Bucket=BUCKET_NAME, Key=FILE_KEY)\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "csv_content = response[\"Body\"].read().decode(\"utf-8\")\n",
    "df = pd.read_csv(StringIO(csv_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>prescription_start</th>\n",
       "      <th>prescription_rx_embeddings</th>\n",
       "      <th>prescription_dose_val_rx</th>\n",
       "      <th>prescription_dose_unit_rx</th>\n",
       "      <th>pre_charttime</th>\n",
       "      <th>pre_ph</th>\n",
       "      <th>pre_pco2</th>\n",
       "      <th>pre_po2</th>\n",
       "      <th>pre_bicarbonate</th>\n",
       "      <th>...</th>\n",
       "      <th>post_fio2_chartevents</th>\n",
       "      <th>post_aado2_calc</th>\n",
       "      <th>post_pao2fio2</th>\n",
       "      <th>post_temperature</th>\n",
       "      <th>post_fio2</th>\n",
       "      <th>post_aado2</th>\n",
       "      <th>post_carboxyhemoglobin</th>\n",
       "      <th>post_methemoglobin</th>\n",
       "      <th>post_calcium</th>\n",
       "      <th>post_intubated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10013</td>\n",
       "      <td>2125-10-05T00:00:00</td>\n",
       "      <td>[ 3.5185558e-01  1.2351961e-01 -1.2304356e-01 ...</td>\n",
       "      <td>0.010317</td>\n",
       "      <td>3</td>\n",
       "      <td>2125-10-04T23:59:00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.023018</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.527567</td>\n",
       "      <td>0.548553</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10013</td>\n",
       "      <td>2125-10-05T00:00:00</td>\n",
       "      <td>[ 0.45182744  0.3218944  -0.5210766   0.315588...</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>4</td>\n",
       "      <td>2125-10-04T23:59:00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.023018</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.527567</td>\n",
       "      <td>0.548553</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10013</td>\n",
       "      <td>2125-10-05T00:00:00</td>\n",
       "      <td>[ 4.5976555e-01  1.9232908e-01 -5.7382131e-01 ...</td>\n",
       "      <td>0.009921</td>\n",
       "      <td>2</td>\n",
       "      <td>2125-10-04T23:59:00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.023018</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.527567</td>\n",
       "      <td>0.548553</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10013</td>\n",
       "      <td>2125-10-05T00:00:00</td>\n",
       "      <td>[ 6.26637757e-01  2.61670560e-01 -2.40684357e-...</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>3</td>\n",
       "      <td>2125-10-04T23:59:00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.023018</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.527567</td>\n",
       "      <td>0.548553</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10013</td>\n",
       "      <td>2125-10-05T00:00:00</td>\n",
       "      <td>[ 4.15423244e-01 -1.28793076e-01 -2.01883331e-...</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>3</td>\n",
       "      <td>2125-10-04T23:59:00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.023018</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.527567</td>\n",
       "      <td>0.548553</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id   prescription_start  \\\n",
       "0       10013  2125-10-05T00:00:00   \n",
       "1       10013  2125-10-05T00:00:00   \n",
       "2       10013  2125-10-05T00:00:00   \n",
       "3       10013  2125-10-05T00:00:00   \n",
       "4       10013  2125-10-05T00:00:00   \n",
       "\n",
       "                          prescription_rx_embeddings  \\\n",
       "0  [ 3.5185558e-01  1.2351961e-01 -1.2304356e-01 ...   \n",
       "1  [ 0.45182744  0.3218944  -0.5210766   0.315588...   \n",
       "2  [ 4.5976555e-01  1.9232908e-01 -5.7382131e-01 ...   \n",
       "3  [ 6.26637757e-01  2.61670560e-01 -2.40684357e-...   \n",
       "4  [ 4.15423244e-01 -1.28793076e-01 -2.01883331e-...   \n",
       "\n",
       "   prescription_dose_val_rx  prescription_dose_unit_rx        pre_charttime  \\\n",
       "0                  0.010317                          3  2125-10-04T23:59:00   \n",
       "1                  0.011905                          4  2125-10-04T23:59:00   \n",
       "2                  0.009921                          2  2125-10-04T23:59:00   \n",
       "3                  0.017857                          3  2125-10-04T23:59:00   \n",
       "4                  0.020833                          3  2125-10-04T23:59:00   \n",
       "\n",
       "   pre_ph  pre_pco2   pre_po2  pre_bicarbonate  ...  post_fio2_chartevents  \\\n",
       "0     0.5  0.741935  0.023018              0.0  ...               0.866667   \n",
       "1     0.5  0.741935  0.023018              0.0  ...               0.866667   \n",
       "2     0.5  0.741935  0.023018              0.0  ...               0.866667   \n",
       "3     0.5  0.741935  0.023018              0.0  ...               0.866667   \n",
       "4     0.5  0.741935  0.023018              0.0  ...               0.866667   \n",
       "\n",
       "   post_aado2_calc  post_pao2fio2  post_temperature  post_fio2  post_aado2  \\\n",
       "0         0.527567       0.548553               0.0        0.0         0.0   \n",
       "1         0.527567       0.548553               0.0        0.0         0.0   \n",
       "2         0.527567       0.548553               0.0        0.0         0.0   \n",
       "3         0.527567       0.548553               0.0        0.0         0.0   \n",
       "4         0.527567       0.548553               0.0        0.0         0.0   \n",
       "\n",
       "   post_carboxyhemoglobin  post_methemoglobin  post_calcium  post_intubated  \n",
       "0                     0.0                 0.0           0.0             0.0  \n",
       "1                     0.0                 0.0           0.0             0.0  \n",
       "2                     0.0                 0.0           0.0             0.0  \n",
       "3                     0.0                 0.0           0.0             0.0  \n",
       "4                     0.0                 0.0           0.0             0.0  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [ 3.5185558e-01  1.2351961e-01 -1.2304356e-01 ...\n",
      "1    [ 0.45182744  0.3218944  -0.5210766   0.315588...\n",
      "2    [ 4.5976555e-01  1.9232908e-01 -5.7382131e-01 ...\n",
      "3    [ 6.26637757e-01  2.61670560e-01 -2.40684357e-...\n",
      "4    [ 4.15423244e-01 -1.28793076e-01 -2.01883331e-...\n",
      "Name: prescription_rx_embeddings, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 3.5185558e-01,  1.2351961e-01, -1.2304356e-01, -3.3200896e-01,\n",
       "       -1.0614018e+00,  1.9121327e-01,  2.7952591e-01,  1.0901182e-02,\n",
       "       -4.5522165e-01, -6.9268858e-01,  1.5272896e-01, -6.2518787e-01,\n",
       "       -5.0267065e-01,  2.3799901e-01,  3.2225102e-01,  3.5973153e-01,\n",
       "       -8.7883368e-02, -6.6698366e-01,  1.2195622e+00,  3.2569757e-01,\n",
       "       -9.7169526e-02, -9.6203506e-01,  7.8181475e-01,  3.1520061e+00,\n",
       "        1.0999583e+00,  8.8330621e-01, -1.3076260e+00, -1.1109836e+00,\n",
       "       -2.1281254e+00,  5.1991540e-01, -1.2142467e+00, -9.5872365e-02,\n",
       "       -2.3115242e-01,  9.2357832e-01,  7.1854466e-01, -4.1259676e-01,\n",
       "       -7.4190390e-01,  1.6999608e+00,  4.8031932e-01,  8.1066114e-01,\n",
       "       -1.0656835e+00, -2.8141283e-03, -5.6771725e-01,  4.5298275e-01,\n",
       "        2.2276033e-01,  4.5889392e-02, -2.4509761e-01, -1.4576931e-01,\n",
       "        6.5086001e-01,  1.1289541e-01,  4.4198048e-01, -8.2376510e-01,\n",
       "       -4.1519284e-01,  4.0492430e-01,  1.8494433e-01, -5.1815975e-01,\n",
       "       -3.0867338e-01,  3.4281105e-02,  3.9996529e-01,  4.9405372e-01,\n",
       "       -1.4286160e-01,  1.3278668e-01,  1.0064495e+00,  2.5586310e-01,\n",
       "       -3.9866152e-01,  8.2304096e-01,  6.2959397e-01,  3.1616542e-02,\n",
       "        7.2930232e-02,  3.2186785e-01,  5.7265061e-01,  4.4384030e-01,\n",
       "       -3.3529732e-01, -6.7583317e-01,  1.3389960e-01, -5.4364049e-01,\n",
       "       -1.4364105e-01, -3.8679227e-01,  1.8466482e-01, -1.5926294e-01,\n",
       "        1.9850397e-01,  2.0364714e-01,  3.9721534e-02, -2.7900195e-01,\n",
       "        1.8685018e-01, -6.7008322e-01, -9.1001445e-01,  2.4761036e-01,\n",
       "        1.8750077e+00,  2.4157475e-01,  8.1599724e-01, -2.8576997e-01,\n",
       "       -3.5283658e-01,  4.0823743e-01,  3.3939067e-01, -1.4805645e-01,\n",
       "        6.8024856e-01,  5.5050582e-01, -9.3816543e-01,  6.3005467e-03,\n",
       "       -3.9748889e-01,  5.2459739e-02,  1.3258077e-01, -5.7579929e-01,\n",
       "       -4.1751972e-01,  1.0518454e+00, -2.9579854e-01, -4.1455862e-01,\n",
       "       -1.7410149e-01, -3.0209619e-01, -2.8416156e-03,  3.7295076e-01,\n",
       "       -4.1972908e-01,  5.1715851e-01, -1.8112589e-01, -1.7690785e-01,\n",
       "        5.4108816e-01,  1.7892011e+00,  9.2282218e-01,  1.9480290e-01,\n",
       "        1.1124935e+00, -1.0893373e+00, -1.0714204e-01, -3.7322634e-01,\n",
       "       -3.4401992e-01,  3.2880038e-01,  4.6848986e-01, -1.0744317e+00])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "def clean_and_convert(x):\n",
    "    if isinstance(x, np.ndarray):  # If already a NumPy array, return as-is\n",
    "        return x\n",
    "    if isinstance(x, str):  # Only process strings\n",
    "        try:\n",
    "            x = re.sub(r'[\\[\\]]', '', x)  # Remove square brackets\n",
    "            cleaned = re.sub(r'\\s+', ' ', x.strip())  # Remove extra spaces\n",
    "            return np.array([float(i) for i in cleaned.split(' ')])  # Convert to NumPy array\n",
    "        except Exception as e:\n",
    "            return x  # Return original value in case of error\n",
    "    return x  # If NaN or unexpected type, return as-is\n",
    "\n",
    "# Check the values before applying the function\n",
    "print(df['prescription_rx_embeddings'].head())\n",
    "\n",
    "# Apply the function to the 'prescription_rx_embeddings' column\n",
    "df['prescription_rx_embeddings'] = df['prescription_rx_embeddings'].apply(clean_and_convert)\n",
    "\n",
    "# Check the result\n",
    "df['prescription_rx_embeddings'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that gets the unique pairs of subject_id and prescription_start\n",
    "def get_unique_pairs(df):\n",
    "    subject_ids = df['subject_id'].unique()\n",
    "    patient_date_pairs = {id: set() for id in subject_ids}\n",
    "\n",
    "    for subj in subject_ids:\n",
    "        df[df['subject_id'] == subj]['prescription_start'].apply(lambda x: patient_date_pairs[subj].add(x))\n",
    "        # convert set to list\n",
    "        patient_date_pairs[subj] = list(patient_date_pairs[subj])\n",
    "    return patient_date_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that gets the prescription array with the proper format\n",
    "def get_presc_input(df):\n",
    "    prescriptions = []\n",
    "        \n",
    "    # Iterate through rows of the DataFrame\n",
    "    for _, row in df.iterrows():\n",
    "        # Extract values from each row\n",
    "        presc = row['prescription_rx_embeddings']\n",
    "        dose_val = row['prescription_dose_val_rx']\n",
    "        dose_unit = row['prescription_dose_unit_rx']\n",
    "        \n",
    "        # Concatenate the prescription embedding with the dose value and unit\n",
    "        combined = np.concatenate((presc, np.array([dose_val, dose_unit])))\n",
    "        prescriptions.append(combined)\n",
    "    \n",
    "    # Convert list to numpy array\n",
    "    prescriptions = np.array(prescriptions)\n",
    "\n",
    "    return prescriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that adds the proper padding to our input arrays\n",
    "def add_padding(prescriptions, pre_treatment, post_treatment):\n",
    "    # reshape pre_treatment and post_treatment to be 2D arrays\n",
    "    pre_treatment = pre_treatment.reshape(1, -1)\n",
    "    post_treatment = post_treatment.reshape(1, -1)\n",
    "    \n",
    "    # Pad or truncate to 20 rows\n",
    "    if prescriptions.shape[0] < 20:\n",
    "        # Pad with zeros to reach 20 rows\n",
    "        prescriptions = np.pad(prescriptions, ((0, 20 - prescriptions.shape[0]), (0, 0)), mode='constant')\n",
    "    elif prescriptions.shape[0] > 20:\n",
    "        # Truncate to 20 rows\n",
    "        prescriptions = prescriptions[:20, :]\n",
    "    \n",
    "    # Pad pre_treatment and post_treatment to 20 rows\n",
    "    pre_treatment = np.pad(pre_treatment, ((0, 19), (0, 0)), mode='constant')  # pad to (20, 25)\n",
    "    post_treatment = np.pad(post_treatment, ((0, 19), (0, 0)), mode='constant')  # pad to (20, 25)\n",
    "    \n",
    "    # Now pad columns to reach 180 features for each\n",
    "    padded_prescriptions = np.pad(prescriptions, ((0, 0), (0, 0)), mode='constant')\n",
    "    padded_pre_treatment = np.pad(pre_treatment, ((0, 0), (0, 105)), mode='constant')\n",
    "    padded_post_treatment = np.pad(post_treatment, ((0, 0), (0, 105)), mode='constant') \n",
    "    \n",
    "    return padded_prescriptions, padded_pre_treatment, padded_post_treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_training_data(df):\n",
    "    # Clean and convert the DataFrame\n",
    "    df['prescription_rx_embeddings'] = df['prescription_rx_embeddings'].apply(clean_and_convert)\n",
    "\n",
    "    # Get unique patient/date pairs\n",
    "    patient_date_pairs = get_unique_pairs(df)\n",
    "    \n",
    "    X_train_list = []\n",
    "    y_train_list = []\n",
    "    \n",
    "    # Iterate through the patient/date pairs\n",
    "    for patient in patient_date_pairs:\n",
    "        for date in patient_date_pairs[patient]:\n",
    "            # Get the data for the current patient/date pair\n",
    "            patient_data = df[(df['subject_id'] == patient) & (df['prescription_start'] == date)]\n",
    "            \n",
    "            if len(patient_data) == 0:\n",
    "                continue\n",
    "                \n",
    "            # Drop unnecessary columns for processing\n",
    "            processing_data = patient_data.drop(['subject_id', 'prescription_start', 'pre_charttime', 'post_charttime'], axis=1)\n",
    "            \n",
    "            # Get the prescription input (2DArray with shape (num_prescriptions, 130))\n",
    "            prescriptions = get_presc_input(processing_data)\n",
    "            \n",
    "            # pre_treatment and post_treatment are 1D arrays\n",
    "            pre_treatment = np.array(processing_data[[col for col in processing_data.columns if col.startswith('pre_')]].values[0])\n",
    "            post_treatment = np.array(processing_data[[col for col in processing_data.columns if col.startswith('post_')]].values[0])\n",
    "            \n",
    "            # Add padding to the inputs\n",
    "            padded_prescriptions, padded_pre_treatment, padded_post_treatment = add_padding(prescriptions, pre_treatment, post_treatment)\n",
    "            \n",
    "            # Create the full sequence (1 patient, 3 time steps, 180 features)\n",
    "            X = np.array([[\n",
    "                padded_pre_treatment,     # Time Step 1: Pre-Treatment\n",
    "                padded_prescriptions,     # Time Step 2: Prescription\n",
    "                padded_post_treatment     # Time Step 3: Post-Treatment\n",
    "            ]])\n",
    "            \n",
    "            y = X[:, -1, :]  # Target is the last time step (Post-Treatment)\n",
    "            \n",
    "            X_train_list.append(X[0])\n",
    "            y_train_list.append(y[0])\n",
    "    \n",
    "    return np.array(X_train_list), np.array(y_train_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "# Function to calculate mean\n",
    "def calculate_mean(df1, df2):\n",
    "    return df1.mean(), df2.mean()\n",
    "\n",
    "# Function to calculate median\n",
    "def calculate_median(df1, df2):\n",
    "    return df1.median(), df2.median()\n",
    "\n",
    "# Function to calculate standard deviation\n",
    "def calculate_std(df1, df2):\n",
    "    return df1.std(), df2.std()\n",
    "\n",
    "# Function to calculate skewness\n",
    "def calculate_skewness(df1, df2):\n",
    "    return df1.apply(lambda x: skew(x, nan_policy='omit')), df2.apply(lambda x: skew(x, nan_policy='omit'))\n",
    "\n",
    "# Function to calculate kurtosis\n",
    "def calculate_kurtosis(df1, df2):\n",
    "    return df1.apply(lambda x: kurtosis(x, nan_policy='omit')), df2.apply(lambda x: kurtosis(x, nan_policy='omit'))\n",
    "\n",
    "# Function to calculate Chi-Square Test for categorical data\n",
    "def calculate_chi_square(df1, df2, cat_column1, cat_column2):\n",
    "    # Create contingency tables for both DataFrames\n",
    "    contingency_table1 = pd.crosstab(df1[cat_column1], df1[cat_column2])\n",
    "    contingency_table2 = pd.crosstab(df2[cat_column1], df2[cat_column2])\n",
    "    \n",
    "    # Perform Chi-Square test for both\n",
    "    chi2_stat1, p_value1, dof1, expected1 = chi2_contingency(contingency_table1)\n",
    "    chi2_stat2, p_value2, dof2, expected2 = chi2_contingency(contingency_table2)\n",
    "    \n",
    "    # Return the results\n",
    "    return {\n",
    "        \"Chi2 Statistic (df)\": chi2_stat1,\n",
    "        \"P-value (df)\": p_value1,\n",
    "        \"Degrees of Freedom (df)\": dof1,\n",
    "        \"Expected Frequencies (df)\": expected1,\n",
    "        \"Chi2 Statistic (new df)\": chi2_stat2,\n",
    "        \"P-value (new df)\": p_value2,\n",
    "        \"Degrees of Freedom (new df)\": dof2,\n",
    "        \"Expected Frequencies (new df)\": expected2\n",
    "    }\n",
    "\n",
    "# Function to find columns with error % greater than threshold across all statistics\n",
    "def find_error_range_columns(df1, df2, threshold=0.02):\n",
    "    range_error_columns = set(df1.columns)\n",
    "    \n",
    "    for stat_func in [calculate_mean, calculate_median, calculate_std, calculate_skewness, calculate_kurtosis]:\n",
    "        stat_df1, stat_df2 = stat_func(df1, df2)\n",
    "        error_diff = abs((stat_df1 - stat_df2) / stat_df1)\n",
    "        # Columns where error is >= threshold\n",
    "        range_error_cols = error_diff[(error_diff >= threshold)].index\n",
    "        range_error_columns.intersection_update(set(range_error_cols))  # Keep only common range-error columns\n",
    "    \n",
    "    # Print results\n",
    "    if range_error_columns:\n",
    "        print(f\"\\nColumns with Error Greater than {threshold} Across All Statistics:\")\n",
    "        for col in sorted(range_error_columns):\n",
    "            print(f\"- {col}\")\n",
    "    else:\n",
    "        print(f\"\\nNo columns have error greater than {threshold} across all statistics.\")\n",
    "    \n",
    "    return range_error_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Update train_model function to use these new functions\n",
    "def train_model(df, model, epochs=10, job_name=None):\n",
    "    X, y = prepare_training_data(df)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train, \n",
    "        epochs=epochs, \n",
    "        batch_size=1, \n",
    "        validation_data=(X_val, y_val)\n",
    "    )\n",
    "\n",
    "    y_pred = model.predict(X_val)\n",
    "\n",
    "    for i in range(len(y_pred)):\n",
    "        df1 = pd.DataFrame(y_val[i])\n",
    "        df2 = pd.DataFrame(y_pred[i])\n",
    "\n",
    "        print(f\"\\nSample {i} Comparison:\")\n",
    "        find_error_range_columns(df1, df2, 0.02)\n",
    "\n",
    "        # print(\"Mean Comparison for sample \", i)\n",
    "        # mean_val, mean_pred = calculate_mean(df1, df2)\n",
    "        # print(f\"y_val Mean: \\n{mean_val}\")\n",
    "        # print(f\"y_pred Mean: \\n{mean_pred}\")\n",
    "\n",
    "        # print(\"\\nMedian Comparison for sample \", i)\n",
    "        # median_val, median_pred = calculate_median(df1, df2)\n",
    "        # print(f\"y_val Median: \\n{median_val}\")\n",
    "        # print(f\"y_pred Median: \\n{median_pred}\")\n",
    "\n",
    "        # print(\"\\nStandard Deviation Comparison for sample \", i)\n",
    "        # std_val, std_pred = calculate_std(df1, df2)\n",
    "        # print(f\"y_val Std: \\n{std_val}\")\n",
    "        # print(f\"y_pred Std: \\n{std_pred}\")\n",
    "\n",
    "        # print(\"\\nSkewness Comparison for sample \", i)\n",
    "        # skew_val, skew_pred = calculate_skewness(df1, df2)\n",
    "        # print(f\"y_val Skewness: \\n{skew_val}\")\n",
    "        # print(f\"y_pred Skewness: \\n{skew_pred}\")\n",
    "\n",
    "        # print(\"\\nKurtosis Comparison for sample \", i)\n",
    "        # kurt_val, kurt_pred = calculate_kurtosis(df1, df2)\n",
    "        # print(f\"y_val Kurtosis: \\n{kurt_val}\")\n",
    "        # print(f\"y_pred Kurtosis: \\n{kurt_pred}\")\n",
    "\n",
    "        # print(\"\\nChi-Square Test for sample \", i)\n",
    "        # chi_square_results = calculate_chi_square(df1, df2, 'prescription_dose_val_rx', 'prescription_dose_unit_rx')\n",
    "        # print(f\"Chi-Square Results: {chi_square_results}\")\n",
    "    \n",
    "    print(f\"History: {history.history}\")\n",
    "    \n",
    "    return history.history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/bb_dev/lib/python3.12/site-packages/keras/src/layers/core/wrapper.py:27: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ time_distributed                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2600</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">682,240</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2600</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">169,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ time_distributed                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m2600\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │       \u001b[38;5;34m682,240\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2600\u001b[0m)           │       \u001b[38;5;34m169,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape (\u001b[38;5;33mReshape\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m130\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">851,240</span> (3.25 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m851,240\u001b[0m (3.25 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">851,240</span> (3.25 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m851,240\u001b[0m (3.25 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0015 - val_loss: 5.4563e-04\n",
      "Epoch 2/10\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4.8257e-04 - val_loss: 4.6287e-04\n",
      "Epoch 3/10\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.6930e-04 - val_loss: 3.8066e-04\n",
      "Epoch 4/10\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.0300e-04 - val_loss: 3.2204e-04\n",
      "Epoch 5/10\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.2926e-04 - val_loss: 2.9333e-04\n",
      "Epoch 6/10\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.4259e-04 - val_loss: 2.6871e-04\n",
      "Epoch 7/10\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.4313e-04 - val_loss: 2.6734e-04\n",
      "Epoch 8/10\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.5154e-04 - val_loss: 2.4863e-04\n",
      "Epoch 9/10\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.3694e-04 - val_loss: 2.3795e-04\n",
      "Epoch 10/10\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.0678e-04 - val_loss: 2.2835e-04\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\n",
      "Sample 0 Comparison:\n",
      "\n",
      "Columns with Error Greater than 0.02 Across All Statistics:\n",
      "- 2\n",
      "\n",
      "Sample 1 Comparison:\n",
      "\n",
      "No columns have error greater than 0.02 across all statistics.\n",
      "\n",
      "Sample 2 Comparison:\n",
      "\n",
      "No columns have error greater than 0.02 across all statistics.\n",
      "\n",
      "Sample 3 Comparison:\n",
      "\n",
      "Columns with Error Greater than 0.02 Across All Statistics:\n",
      "- 2\n",
      "\n",
      "Sample 4 Comparison:\n",
      "\n",
      "No columns have error greater than 0.02 across all statistics.\n",
      "\n",
      "Sample 5 Comparison:\n",
      "\n",
      "No columns have error greater than 0.02 across all statistics.\n",
      "\n",
      "Sample 6 Comparison:\n",
      "\n",
      "No columns have error greater than 0.02 across all statistics.\n",
      "\n",
      "Sample 7 Comparison:\n",
      "\n",
      "No columns have error greater than 0.02 across all statistics.\n",
      "\n",
      "Sample 8 Comparison:\n",
      "\n",
      "No columns have error greater than 0.02 across all statistics.\n",
      "\n",
      "Sample 9 Comparison:\n",
      "\n",
      "No columns have error greater than 0.02 across all statistics.\n",
      "\n",
      "Sample 10 Comparison:\n",
      "\n",
      "No columns have error greater than 0.02 across all statistics.\n",
      "\n",
      "Sample 11 Comparison:\n",
      "\n",
      "No columns have error greater than 0.02 across all statistics.\n",
      "\n",
      "Sample 12 Comparison:\n",
      "\n",
      "No columns have error greater than 0.02 across all statistics.\n",
      "\n",
      "Sample 13 Comparison:\n",
      "\n",
      "No columns have error greater than 0.02 across all statistics.\n",
      "\n",
      "Sample 14 Comparison:\n",
      "\n",
      "Columns with Error Greater than 0.02 Across All Statistics:\n",
      "- 2\n",
      "\n",
      "Sample 15 Comparison:\n",
      "\n",
      "Columns with Error Greater than 0.02 Across All Statistics:\n",
      "- 13\n",
      "\n",
      "Sample 16 Comparison:\n",
      "\n",
      "No columns have error greater than 0.02 across all statistics.\n",
      "\n",
      "Sample 17 Comparison:\n",
      "\n",
      "No columns have error greater than 0.02 across all statistics.\n",
      "\n",
      "Sample 18 Comparison:\n",
      "\n",
      "No columns have error greater than 0.02 across all statistics.\n",
      "\n",
      "Sample 19 Comparison:\n",
      "\n",
      "No columns have error greater than 0.02 across all statistics.\n",
      "\n",
      "Sample 20 Comparison:\n",
      "\n",
      "No columns have error greater than 0.02 across all statistics.\n",
      "\n",
      "Sample 21 Comparison:\n",
      "\n",
      "No columns have error greater than 0.02 across all statistics.\n",
      "\n",
      "Sample 22 Comparison:\n",
      "\n",
      "No columns have error greater than 0.02 across all statistics.\n",
      "\n",
      "Sample 23 Comparison:\n",
      "\n",
      "No columns have error greater than 0.02 across all statistics.\n",
      "\n",
      "Sample 24 Comparison:\n",
      "\n",
      "Columns with Error Greater than 0.02 Across All Statistics:\n",
      "- 2\n",
      "\n",
      "Sample 25 Comparison:\n",
      "\n",
      "No columns have error greater than 0.02 across all statistics.\n",
      "\n",
      "Sample 26 Comparison:\n",
      "\n",
      "No columns have error greater than 0.02 across all statistics.\n",
      "\n",
      "Sample 27 Comparison:\n",
      "\n",
      "No columns have error greater than 0.02 across all statistics.\n",
      "\n",
      "Sample 28 Comparison:\n",
      "\n",
      "No columns have error greater than 0.02 across all statistics.\n",
      "\n",
      "Sample 29 Comparison:\n",
      "\n",
      "No columns have error greater than 0.02 across all statistics.\n",
      "\n",
      "Sample 30 Comparison:\n",
      "\n",
      "No columns have error greater than 0.02 across all statistics.\n",
      "\n",
      "Sample 31 Comparison:\n",
      "\n",
      "No columns have error greater than 0.02 across all statistics.\n",
      "\n",
      "Sample 32 Comparison:\n",
      "\n",
      "No columns have error greater than 0.02 across all statistics.\n",
      "\n",
      "Sample 33 Comparison:\n",
      "\n",
      "No columns have error greater than 0.02 across all statistics.\n",
      "\n",
      "Sample 34 Comparison:\n",
      "\n",
      "No columns have error greater than 0.02 across all statistics.\n",
      "\n",
      "Sample 35 Comparison:\n",
      "\n",
      "No columns have error greater than 0.02 across all statistics.\n",
      "\n",
      "Sample 36 Comparison:\n",
      "\n",
      "No columns have error greater than 0.02 across all statistics.\n",
      "\n",
      "Sample 37 Comparison:\n",
      "\n",
      "No columns have error greater than 0.02 across all statistics.\n",
      "\n",
      "Sample 38 Comparison:\n",
      "\n",
      "Columns with Error Greater than 0.02 Across All Statistics:\n",
      "- 9\n",
      "- 23\n",
      "\n",
      "Sample 39 Comparison:\n",
      "\n",
      "No columns have error greater than 0.02 across all statistics.\n",
      "\n",
      "Sample 40 Comparison:\n",
      "\n",
      "No columns have error greater than 0.02 across all statistics.\n",
      "\n",
      "Sample 41 Comparison:\n",
      "\n",
      "No columns have error greater than 0.02 across all statistics.\n",
      "\n",
      "Sample 42 Comparison:\n",
      "\n",
      "No columns have error greater than 0.02 across all statistics.\n",
      "\n",
      "Sample 43 Comparison:\n",
      "\n",
      "No columns have error greater than 0.02 across all statistics.\n",
      "\n",
      "Sample 44 Comparison:\n",
      "\n",
      "No columns have error greater than 0.02 across all statistics.\n",
      "\n",
      "Sample 45 Comparison:\n",
      "\n",
      "No columns have error greater than 0.02 across all statistics.\n",
      "\n",
      "Sample 46 Comparison:\n",
      "\n",
      "No columns have error greater than 0.02 across all statistics.\n",
      "\n",
      "Sample 47 Comparison:\n",
      "\n",
      "Columns with Error Greater than 0.02 Across All Statistics:\n",
      "- 8\n",
      "- 10\n",
      "- 11\n",
      "\n",
      "Sample 48 Comparison:\n",
      "\n",
      "No columns have error greater than 0.02 across all statistics.\n",
      "\n",
      "Sample 49 Comparison:\n",
      "\n",
      "No columns have error greater than 0.02 across all statistics.\n",
      "\n",
      "Sample 50 Comparison:\n",
      "\n",
      "No columns have error greater than 0.02 across all statistics.\n",
      "\n",
      "Sample 51 Comparison:\n",
      "\n",
      "No columns have error greater than 0.02 across all statistics.\n",
      "\n",
      "Sample 52 Comparison:\n",
      "\n",
      "No columns have error greater than 0.02 across all statistics.\n",
      "\n",
      "Sample 53 Comparison:\n",
      "\n",
      "No columns have error greater than 0.02 across all statistics.\n",
      "\n",
      "Sample 54 Comparison:\n",
      "\n",
      "Columns with Error Greater than 0.02 Across All Statistics:\n",
      "- 2\n",
      "\n",
      "Sample 55 Comparison:\n",
      "\n",
      "Columns with Error Greater than 0.02 Across All Statistics:\n",
      "- 2\n",
      "\n",
      "Sample 56 Comparison:\n",
      "\n",
      "No columns have error greater than 0.02 across all statistics.\n",
      "History: {'loss': [0.001076901564374566, 0.0004954329342581332, 0.00035313080297783017, 0.0002603117609396577, 0.0002055255463346839, 0.00016504204540979117, 0.0001420290645910427, 0.00014618749264627695, 0.00012739741941913962, 9.740119276102632e-05], 'val_loss': [0.0005456307553686202, 0.0004628680762834847, 0.0003806631430052221, 0.00032203891896642745, 0.00029332705889828503, 0.00026871133013628423, 0.0002673420822247863, 0.00024862663121894, 0.00023794587468728423, 0.00022834530682303011]}\n",
      "{'loss': [0.001076901564374566, 0.0004954329342581332, 0.00035313080297783017, 0.0002603117609396577, 0.0002055255463346839, 0.00016504204540979117, 0.0001420290645910427, 0.00014618749264627695, 0.00012739741941913962, 9.740119276102632e-05], 'val_loss': [0.0005456307553686202, 0.0004628680762834847, 0.0003806631430052221, 0.00032203891896642745, 0.00029332705889828503, 0.00026871133013628423, 0.0002673420822247863, 0.00024862663121894, 0.00023794587468728423, 0.00022834530682303011]}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, TimeDistributed, Flatten, Reshape\n",
    "\n",
    "# input shape is (3, 20, 130)\n",
    "# We flatten each time step, process the 3 time steps with an LSTM,\n",
    "# and then use a Dense layer to output 20*130 values reshaped to (20, 130)\n",
    "model = Sequential([\n",
    "    TimeDistributed(Flatten(), input_shape=(3, 20, 130)),\n",
    "    LSTM(64, return_sequences=False),\n",
    "    Dropout(0.2),\n",
    "    Dense(20 * 130, activation=\"linear\"),\n",
    "    Reshape((20, 130))\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n",
    "\n",
    "# Uncomment to train the model when ready\n",
    "history = train_model(df, model)\n",
    "print(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bb_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
